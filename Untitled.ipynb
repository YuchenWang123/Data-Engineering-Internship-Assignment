{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries: urllib2 is used to query a website, BeautifulSoup is used to parse the data, \n",
    "# pandas is used to construct dataframes, and string is used to manage the data\n",
    "import urllib.request as urllib2\n",
    "import pandas as pd\n",
    "import string\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the url\n",
    "wiki = \"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\"\n",
    "\n",
    "#Query the website and return the html to the variable 'page'\n",
    "page = urllib2.urlopen(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all tables\n",
    "all_tables=soup.find_all('table')\n",
    "\n",
    "# Find the right table\n",
    "right_table=soup.find('table', class_=\"wikitable sortable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the punctuations except \"+\", \"-\" and \".\"\n",
    "punc = string.punctuation[0:10]+string.punctuation[11:12]+string.punctuation[14:-1]\n",
    "\n",
    "# Construct lists to store the data\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "E=[]\n",
    "F=[]\n",
    "G=[]\n",
    "H=[]\n",
    "I=[]\n",
    "J=[]\n",
    "K=[]\n",
    "L=[]\n",
    "\n",
    "for row in right_table.findAll(\"tr\")[1:]: # Since we will define the column names by ourselves, we only extract the data from second row, \n",
    "    cells = row.findAll('td')                #  without the column names from the website.\n",
    "   \n",
    "    A.append(int(cells[0].text[0:-1]))\n",
    "    B.append(cells[1].text[0:-1].split(\"[\")[0])\n",
    "    C.append(cells[2].text[1:-1])\n",
    "    D.append(float(''.join(c for c in cells[3].text[0:-1] if c not in punc)))\n",
    "    E.append(float(''.join(c for c in cells[4].text[0:-1] if c not in punc)))\n",
    "    if cells[5].text[0] == '+':\n",
    "        F.append(float(cells[5].text[0:-2]))\n",
    "    elif cells[5].text[0] == 'âˆ’' :\n",
    "        F.append(-float(cells[5].text[1:-2]))\n",
    "    else:\n",
    "        F.append(\" \")\n",
    "    G.append(float(''.join(c for c in cells[6].text.split()[0] if c not in punc)))\n",
    "    H.append(float(''.join(c for c in cells[7].text.split()[0] if c not in punc)))\n",
    "    I.append(float(''.join(c for c in cells[8].text.split(\"/\")[0].split()[0] if c not in punc)))\n",
    "    J.append(float(''.join(c for c in cells[9].text.split(\"/\")[0].split()[0] if c not in punc)))\n",
    "    K.append(float(''.join(c for c in cells[10].find(\"span\", class_=\"geo\").text if c not in punc).split()[0]))\n",
    "    L.append(-float(''.join(c for c in cells[10].find(\"span\", class_=\"geo\").text if c not in punc).split()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(A, columns=[\"2018 Rank\"])\n",
    "df[\"City\"] = B\n",
    "df[\"State\"] = C\n",
    "df[\"2018 Estimate\"] =D\n",
    "df[\"2010 Census\"] = E\n",
    "df[\"Change (%)\"] = F\n",
    "df[\"2016 Land Area (sq mi)\"]= G\n",
    "df[\"2016 Land Area (km2)\"] = H\n",
    "df[\"2016 Population Density (sq mi)\"] =I\n",
    "df[\"2016 Population Density (km2)\"] = J\n",
    "df[\"Location (N)\"] = K\n",
    "df[\"Location (W)\"] =L\n",
    "\n",
    "df.set_index([\"2018 Rank\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"Data of Cities.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
